{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 2021-02-16_Arhan_AT - Lesson 40","provenance":[{"file_id":"1xOwXSgzChgBhehvCqFPxCuoHPzYPLTHD","timestamp":1613471274484},{"file_id":"1oY8-DPgjTYTALDMVRjrdNO7R7YNxw3in","timestamp":1613468137555}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"z75TncAdaPi8"},"source":["# Lesson 40: Air Quality Analysis - Data Cleaning"]},{"cell_type":"markdown","metadata":{"id":"Wrq9E4BMmOHe"},"source":["### Teacher-Student Activities\n","\n","In this class, we will clean the DataFrame by replacing commas with periods (or dots) and by replacing the `-200` garbage value with the median value of the respective columns.\n","\n","The data cleaning exercises depend on the kind of dataset you get. However, the functions applied or the operations followed to clean a DataFrame more or less remain the same. \n","\n","Let's begin the class by running the code which we have already covered in the previous classes and continue the class from the **Activity 1: Replacing Commas** section."]},{"cell_type":"markdown","metadata":{"id":"xciPkfWVnJcg"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"K6mV_YtknKNB"},"source":["### Recap\n","\n","Run the code cell below to load the dataset and apply the operations on the DataFrame that were covered in the previous classes."]},{"cell_type":"code","metadata":{"id":"wNOjV6SAaMNK","executionInfo":{"status":"ok","timestamp":1613471180751,"user_tz":-330,"elapsed":3175,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}}},"source":["# Run the code cell.\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Loading the dataset.\n","csv_file = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/air-quality/AirQualityUCI.csv'\n","df = pd.read_csv(csv_file, sep=';')\n","\n","# Dropping the 'Unnamed: 15' & 'Unnamed: 16' columns.\n","df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16'], axis=1) \n","\n","# Dropping the null values.\n","df = df.dropna()\n","\n","# Creating a Pandas series containing 'datetime' objects.\n","dt_series = pd.Series(data = [item.split(\"/\")[2] + \"-\" + item.split(\"/\")[1] + \"-\" + item.split(\"/\")[0] for item in df['Date']], index=df.index) + ' ' + pd.Series(data=[str(item).replace(\".\", \":\") for item in df['Time']], index=df.index)\n","dt_series = pd.to_datetime(dt_series)\n","\n","# Remove the Date & Time columns from the DataFrame and insert the 'dt_series' in it.\n","df = df.drop(columns=['Date', 'Time'], axis=1)\n","df.insert(loc=0, column='DateTime', value=dt_series)\n","\n","# Get the Pandas series containing the year values as integers.\n","year_series = dt_series.dt.year\n","\n","# Get the Pandas series containing the month values as integers.\n","month_series = dt_series.dt.month\n","\n","# Get the Pandas series containing the day values as integers.\n","day_series = dt_series.dt.day\n","\n","# Get the Pandas series containing the days of a week, i.e., Monday, Tuesday, Wednesday etc.\n","day_name_series = dt_series.dt.day_name()\n","\n","# Add the 'Year', 'Month', 'Day' and 'Day Name' columns to the DataFrame.\n","df['Year'] = year_series\n","df['Month'] = month_series\n","df['Day'] = day_series\n","df['Day Name'] = day_name_series\n","\n","# Sort the DataFrame by the 'DateTime' values in the ascending order. Also, display the first 10 rows of the DataFrame.\n","df = df.sort_values(by='DateTime')"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Wce1jJAs_23"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"LwuGk4habNWS"},"source":["#### Activity 1: Replacing Commas^\n","\n","The  values in the `CO(GT), C6H6(GT), T,\tRH` and\t`AH` columns contain the commas in them. Let's replace the commas with periods (or dots). "]},{"cell_type":"code","metadata":{"id":"uu1Qollia62D","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"ok","timestamp":1613471180757,"user_tz":-330,"elapsed":3157,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"10d6fc8e-a6d6-4ef1-d331-1350a15cdfe3"},"source":["# S1.1: Display the first five rows of the DataFrame.\n","df.head()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DateTime</th>\n","      <th>CO(GT)</th>\n","      <th>PT08.S1(CO)</th>\n","      <th>NMHC(GT)</th>\n","      <th>C6H6(GT)</th>\n","      <th>PT08.S2(NMHC)</th>\n","      <th>NOx(GT)</th>\n","      <th>PT08.S3(NOx)</th>\n","      <th>NO2(GT)</th>\n","      <th>PT08.S4(NO2)</th>\n","      <th>PT08.S5(O3)</th>\n","      <th>T</th>\n","      <th>RH</th>\n","      <th>AH</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>Day Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2004-03-10 18:00:00</td>\n","      <td>2,6</td>\n","      <td>1360.0</td>\n","      <td>150.0</td>\n","      <td>11,9</td>\n","      <td>1046.0</td>\n","      <td>166.0</td>\n","      <td>1056.0</td>\n","      <td>113.0</td>\n","      <td>1692.0</td>\n","      <td>1268.0</td>\n","      <td>13,6</td>\n","      <td>48,9</td>\n","      <td>0,7578</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2004-03-10 19:00:00</td>\n","      <td>2</td>\n","      <td>1292.0</td>\n","      <td>112.0</td>\n","      <td>9,4</td>\n","      <td>955.0</td>\n","      <td>103.0</td>\n","      <td>1174.0</td>\n","      <td>92.0</td>\n","      <td>1559.0</td>\n","      <td>972.0</td>\n","      <td>13,3</td>\n","      <td>47,7</td>\n","      <td>0,7255</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2004-03-10 20:00:00</td>\n","      <td>2,2</td>\n","      <td>1402.0</td>\n","      <td>88.0</td>\n","      <td>9,0</td>\n","      <td>939.0</td>\n","      <td>131.0</td>\n","      <td>1140.0</td>\n","      <td>114.0</td>\n","      <td>1555.0</td>\n","      <td>1074.0</td>\n","      <td>11,9</td>\n","      <td>54,0</td>\n","      <td>0,7502</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004-03-10 21:00:00</td>\n","      <td>2,2</td>\n","      <td>1376.0</td>\n","      <td>80.0</td>\n","      <td>9,2</td>\n","      <td>948.0</td>\n","      <td>172.0</td>\n","      <td>1092.0</td>\n","      <td>122.0</td>\n","      <td>1584.0</td>\n","      <td>1203.0</td>\n","      <td>11,0</td>\n","      <td>60,0</td>\n","      <td>0,7867</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2004-03-10 22:00:00</td>\n","      <td>1,6</td>\n","      <td>1272.0</td>\n","      <td>51.0</td>\n","      <td>6,5</td>\n","      <td>836.0</td>\n","      <td>131.0</td>\n","      <td>1205.0</td>\n","      <td>116.0</td>\n","      <td>1490.0</td>\n","      <td>1110.0</td>\n","      <td>11,2</td>\n","      <td>59,6</td>\n","      <td>0,7888</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             DateTime CO(GT)  PT08.S1(CO)  ...  Month Day   Day Name\n","0 2004-03-10 18:00:00    2,6       1360.0  ...      3  10  Wednesday\n","1 2004-03-10 19:00:00      2       1292.0  ...      3  10  Wednesday\n","2 2004-03-10 20:00:00    2,2       1402.0  ...      3  10  Wednesday\n","3 2004-03-10 21:00:00    2,2       1376.0  ...      3  10  Wednesday\n","4 2004-03-10 22:00:00    1,6       1272.0  ...      3  10  Wednesday\n","\n","[5 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"3twFa_GCoHrS"},"source":["Create a function which takes a Pandas series containing comma separated decimal values as an input and returns a new Pandas series containing period separated decimal values as an output."]},{"cell_type":"code","metadata":{"id":"qj1ZwNpKbN4g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471180758,"user_tz":-330,"elapsed":3146,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"2db535cf-40cd-44af-ebd5-b6af897382ab"},"source":["# S1.2: Create a function to replace the commas with periods in a Pandas series.\n","def rep(ser):\n","  s1 = pd.Series(data = [float(str(i).replace(',','.'))for i in ser],index = df.index)\n","  return s1\n","\n","rep(df['RH'])\n","\n"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       48.9\n","1       47.7\n","2       54.0\n","3       60.0\n","4       59.6\n","        ... \n","9352    29.3\n","9353    23.7\n","9354    18.3\n","9355    13.5\n","9356    13.1\n","Length: 9357, dtype: float64"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"lTQTLZHFozvM"},"source":["In the above code,\n","\n","- we iterated through each item of a `series`, \n","\n","- converted each item to a string value using the `str()` function, \n","\n","- replaced the comma with the period using the `replace()` function \n","\n","- converted the replaced value to a floating-point number using the `float()` function,\n","\n","- added each item to a Python list, and\n","\n","- converted the list to a Pandas series using the `pd.Series()` function. \n","\n","We have ensured that the indices of the new Pandas series is same as the indices of the DataFrame by passing `index = df.index` parameter to the `pd.Series()` function where `df` is the DataFrame.\n","\n","Now, let's test the `comma_to_period()` function by correcting the values of `CO(GT)` column but storing the output in a new variable so that the original values of the column are unaffected before we have verified the correctness of the function."]},{"cell_type":"code","metadata":{"id":"crtSeoOcqQjM","executionInfo":{"status":"ok","timestamp":1613471180759,"user_tz":-330,"elapsed":3143,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}}},"source":["# S1.3: Test the 'comma_to_period()' function by correcting the values of 'CO(GT)' column but storing the output in a new variable.\n"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4WfW0gDqduB"},"source":["As you can see, all the values of the `CO(GT)` column are now proper float-point numbers. Let's apply the `comma_to_period()` function on the `'CO(GT), C6H6(GT), T, RH` and `AH` columns.\n"]},{"cell_type":"code","metadata":{"id":"3uNxSnOsbVpp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471180759,"user_tz":-330,"elapsed":3131,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"93e99dbe-d00e-43c7-a3ee-ae6c902a7171"},"source":["# S1.4: Apply the 'comma_to_period()' function on the ''CO(GT)', 'C6H6(GT)', 'T', 'RH' and 'AH' columns.\n","l1 = ['CO(GT)', 'C6H6(GT)', 'T', 'RH','AH']\n","for i in l1:\n","  df[i] = rep(df[i])\n","print(df.head())"],"execution_count":26,"outputs":[{"output_type":"stream","text":["             DateTime  CO(GT)  PT08.S1(CO)  ...  Month  Day   Day Name\n","0 2004-03-10 18:00:00     2.6       1360.0  ...      3   10  Wednesday\n","1 2004-03-10 19:00:00     2.0       1292.0  ...      3   10  Wednesday\n","2 2004-03-10 20:00:00     2.2       1402.0  ...      3   10  Wednesday\n","3 2004-03-10 21:00:00     2.2       1376.0  ...      3   10  Wednesday\n","4 2004-03-10 22:00:00     1.6       1272.0  ...      3   10  Wednesday\n","\n","[5 rows x 18 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ul5_3oF7rXve"},"source":["In the above code:\n","\n","- We created a list of all the columns whose values we need to correct.\n","\n","- Itereated through each value of the list.\n","\n","- Applied the `comma_to_period()` function on each column of the `df` DataFrame.\n","\n","- Replaced each column with their corresponding new series to correct the required values.\n","\n","Let's print the first five rows of the DataFrame to see the effect of the `comma_to_period()` function."]},{"cell_type":"code","metadata":{"id":"hJUJVXZ2bZFq","executionInfo":{"status":"ok","timestamp":1613471180760,"user_tz":-330,"elapsed":3129,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}}},"source":["# S1.5: Display the first five rows of the DataFrame to see the effect of the 'comma_to_period()' function.\n"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-oQpK13sg6F"},"source":["Let's also print the information on the `df` DataFrame. Except for the first column and the last column, all other columns must have the numeric (`float` or `int`) data-type values."]},{"cell_type":"code","metadata":{"id":"pd3a-0HJba4g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471180760,"user_tz":-330,"elapsed":3116,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"9e2763ab-4b6c-4f86-fb7c-35fcf5df73a7"},"source":["# S1.6: Print the first information of the 'df' DataFrame.\n","df.info()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 9357 entries, 0 to 9356\n","Data columns (total 18 columns):\n"," #   Column         Non-Null Count  Dtype         \n","---  ------         --------------  -----         \n"," 0   DateTime       9357 non-null   datetime64[ns]\n"," 1   CO(GT)         9357 non-null   float64       \n"," 2   PT08.S1(CO)    9357 non-null   float64       \n"," 3   NMHC(GT)       9357 non-null   float64       \n"," 4   C6H6(GT)       9357 non-null   float64       \n"," 5   PT08.S2(NMHC)  9357 non-null   float64       \n"," 6   NOx(GT)        9357 non-null   float64       \n"," 7   PT08.S3(NOx)   9357 non-null   float64       \n"," 8   NO2(GT)        9357 non-null   float64       \n"," 9   PT08.S4(NO2)   9357 non-null   float64       \n"," 10  PT08.S5(O3)    9357 non-null   float64       \n"," 11  T              9357 non-null   float64       \n"," 12  RH             9357 non-null   float64       \n"," 13  AH             9357 non-null   float64       \n"," 14  Year           9357 non-null   int64         \n"," 15  Month          9357 non-null   int64         \n"," 16  Day            9357 non-null   int64         \n"," 17  Day Name       9357 non-null   object        \n","dtypes: datetime64[ns](1), float64(13), int64(3), object(1)\n","memory usage: 1.4+ MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WX58NHE1tHOA"},"source":["---\n"]},{"cell_type":"markdown","metadata":{"id":"HK42XBR0tIPg"},"source":["#### Acitivity 2: Garbage Value Inspection^^\n","\n","The columns in the `df` DataFrame also contains `-200` value. It is a garbage value or just a random number to represent the further missing (or null) values in the DataFrame. Let's replace it with the most appropriate values for each column."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"t9sNVxvnRRgz","executionInfo":{"status":"ok","timestamp":1613471180761,"user_tz":-330,"elapsed":3102,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"1a292541-48c1-475f-b8e5-3f7e7eb6a2e5"},"source":["df.head(20)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DateTime</th>\n","      <th>CO(GT)</th>\n","      <th>PT08.S1(CO)</th>\n","      <th>NMHC(GT)</th>\n","      <th>C6H6(GT)</th>\n","      <th>PT08.S2(NMHC)</th>\n","      <th>NOx(GT)</th>\n","      <th>PT08.S3(NOx)</th>\n","      <th>NO2(GT)</th>\n","      <th>PT08.S4(NO2)</th>\n","      <th>PT08.S5(O3)</th>\n","      <th>T</th>\n","      <th>RH</th>\n","      <th>AH</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>Day Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2004-03-10 18:00:00</td>\n","      <td>2.6</td>\n","      <td>1360.0</td>\n","      <td>150.0</td>\n","      <td>11.9</td>\n","      <td>1046.0</td>\n","      <td>166.0</td>\n","      <td>1056.0</td>\n","      <td>113.0</td>\n","      <td>1692.0</td>\n","      <td>1268.0</td>\n","      <td>13.6</td>\n","      <td>48.9</td>\n","      <td>0.7578</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2004-03-10 19:00:00</td>\n","      <td>2.0</td>\n","      <td>1292.0</td>\n","      <td>112.0</td>\n","      <td>9.4</td>\n","      <td>955.0</td>\n","      <td>103.0</td>\n","      <td>1174.0</td>\n","      <td>92.0</td>\n","      <td>1559.0</td>\n","      <td>972.0</td>\n","      <td>13.3</td>\n","      <td>47.7</td>\n","      <td>0.7255</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2004-03-10 20:00:00</td>\n","      <td>2.2</td>\n","      <td>1402.0</td>\n","      <td>88.0</td>\n","      <td>9.0</td>\n","      <td>939.0</td>\n","      <td>131.0</td>\n","      <td>1140.0</td>\n","      <td>114.0</td>\n","      <td>1555.0</td>\n","      <td>1074.0</td>\n","      <td>11.9</td>\n","      <td>54.0</td>\n","      <td>0.7502</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004-03-10 21:00:00</td>\n","      <td>2.2</td>\n","      <td>1376.0</td>\n","      <td>80.0</td>\n","      <td>9.2</td>\n","      <td>948.0</td>\n","      <td>172.0</td>\n","      <td>1092.0</td>\n","      <td>122.0</td>\n","      <td>1584.0</td>\n","      <td>1203.0</td>\n","      <td>11.0</td>\n","      <td>60.0</td>\n","      <td>0.7867</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2004-03-10 22:00:00</td>\n","      <td>1.6</td>\n","      <td>1272.0</td>\n","      <td>51.0</td>\n","      <td>6.5</td>\n","      <td>836.0</td>\n","      <td>131.0</td>\n","      <td>1205.0</td>\n","      <td>116.0</td>\n","      <td>1490.0</td>\n","      <td>1110.0</td>\n","      <td>11.2</td>\n","      <td>59.6</td>\n","      <td>0.7888</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2004-03-10 23:00:00</td>\n","      <td>1.2</td>\n","      <td>1197.0</td>\n","      <td>38.0</td>\n","      <td>4.7</td>\n","      <td>750.0</td>\n","      <td>89.0</td>\n","      <td>1337.0</td>\n","      <td>96.0</td>\n","      <td>1393.0</td>\n","      <td>949.0</td>\n","      <td>11.2</td>\n","      <td>59.2</td>\n","      <td>0.7848</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2004-03-11 00:00:00</td>\n","      <td>1.2</td>\n","      <td>1185.0</td>\n","      <td>31.0</td>\n","      <td>3.6</td>\n","      <td>690.0</td>\n","      <td>62.0</td>\n","      <td>1462.0</td>\n","      <td>77.0</td>\n","      <td>1333.0</td>\n","      <td>733.0</td>\n","      <td>11.3</td>\n","      <td>56.8</td>\n","      <td>0.7603</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2004-03-11 01:00:00</td>\n","      <td>1.0</td>\n","      <td>1136.0</td>\n","      <td>31.0</td>\n","      <td>3.3</td>\n","      <td>672.0</td>\n","      <td>62.0</td>\n","      <td>1453.0</td>\n","      <td>76.0</td>\n","      <td>1333.0</td>\n","      <td>730.0</td>\n","      <td>10.7</td>\n","      <td>60.0</td>\n","      <td>0.7702</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2004-03-11 02:00:00</td>\n","      <td>0.9</td>\n","      <td>1094.0</td>\n","      <td>24.0</td>\n","      <td>2.3</td>\n","      <td>609.0</td>\n","      <td>45.0</td>\n","      <td>1579.0</td>\n","      <td>60.0</td>\n","      <td>1276.0</td>\n","      <td>620.0</td>\n","      <td>10.7</td>\n","      <td>59.7</td>\n","      <td>0.7648</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2004-03-11 03:00:00</td>\n","      <td>0.6</td>\n","      <td>1010.0</td>\n","      <td>19.0</td>\n","      <td>1.7</td>\n","      <td>561.0</td>\n","      <td>-200.0</td>\n","      <td>1705.0</td>\n","      <td>-200.0</td>\n","      <td>1235.0</td>\n","      <td>501.0</td>\n","      <td>10.3</td>\n","      <td>60.2</td>\n","      <td>0.7517</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2004-03-11 04:00:00</td>\n","      <td>-200.0</td>\n","      <td>1011.0</td>\n","      <td>14.0</td>\n","      <td>1.3</td>\n","      <td>527.0</td>\n","      <td>21.0</td>\n","      <td>1818.0</td>\n","      <td>34.0</td>\n","      <td>1197.0</td>\n","      <td>445.0</td>\n","      <td>10.1</td>\n","      <td>60.5</td>\n","      <td>0.7465</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2004-03-11 05:00:00</td>\n","      <td>0.7</td>\n","      <td>1066.0</td>\n","      <td>8.0</td>\n","      <td>1.1</td>\n","      <td>512.0</td>\n","      <td>16.0</td>\n","      <td>1918.0</td>\n","      <td>28.0</td>\n","      <td>1182.0</td>\n","      <td>422.0</td>\n","      <td>11.0</td>\n","      <td>56.2</td>\n","      <td>0.7366</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>2004-03-11 06:00:00</td>\n","      <td>0.7</td>\n","      <td>1052.0</td>\n","      <td>16.0</td>\n","      <td>1.6</td>\n","      <td>553.0</td>\n","      <td>34.0</td>\n","      <td>1738.0</td>\n","      <td>48.0</td>\n","      <td>1221.0</td>\n","      <td>472.0</td>\n","      <td>10.5</td>\n","      <td>58.1</td>\n","      <td>0.7353</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>2004-03-11 07:00:00</td>\n","      <td>1.1</td>\n","      <td>1144.0</td>\n","      <td>29.0</td>\n","      <td>3.2</td>\n","      <td>667.0</td>\n","      <td>98.0</td>\n","      <td>1490.0</td>\n","      <td>82.0</td>\n","      <td>1339.0</td>\n","      <td>730.0</td>\n","      <td>10.2</td>\n","      <td>59.6</td>\n","      <td>0.7417</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2004-03-11 08:00:00</td>\n","      <td>2.0</td>\n","      <td>1333.0</td>\n","      <td>64.0</td>\n","      <td>8.0</td>\n","      <td>900.0</td>\n","      <td>174.0</td>\n","      <td>1136.0</td>\n","      <td>112.0</td>\n","      <td>1517.0</td>\n","      <td>1102.0</td>\n","      <td>10.8</td>\n","      <td>57.4</td>\n","      <td>0.7408</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>2004-03-11 09:00:00</td>\n","      <td>2.2</td>\n","      <td>1351.0</td>\n","      <td>87.0</td>\n","      <td>9.5</td>\n","      <td>960.0</td>\n","      <td>129.0</td>\n","      <td>1079.0</td>\n","      <td>101.0</td>\n","      <td>1583.0</td>\n","      <td>1028.0</td>\n","      <td>10.5</td>\n","      <td>60.6</td>\n","      <td>0.7691</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>2004-03-11 10:00:00</td>\n","      <td>1.7</td>\n","      <td>1233.0</td>\n","      <td>77.0</td>\n","      <td>6.3</td>\n","      <td>827.0</td>\n","      <td>112.0</td>\n","      <td>1218.0</td>\n","      <td>98.0</td>\n","      <td>1446.0</td>\n","      <td>860.0</td>\n","      <td>10.8</td>\n","      <td>58.4</td>\n","      <td>0.7552</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>2004-03-11 11:00:00</td>\n","      <td>1.5</td>\n","      <td>1179.0</td>\n","      <td>43.0</td>\n","      <td>5.0</td>\n","      <td>762.0</td>\n","      <td>95.0</td>\n","      <td>1328.0</td>\n","      <td>92.0</td>\n","      <td>1362.0</td>\n","      <td>671.0</td>\n","      <td>10.5</td>\n","      <td>57.9</td>\n","      <td>0.7352</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>2004-03-11 12:00:00</td>\n","      <td>1.6</td>\n","      <td>1236.0</td>\n","      <td>61.0</td>\n","      <td>5.2</td>\n","      <td>774.0</td>\n","      <td>104.0</td>\n","      <td>1301.0</td>\n","      <td>95.0</td>\n","      <td>1401.0</td>\n","      <td>664.0</td>\n","      <td>9.5</td>\n","      <td>66.8</td>\n","      <td>0.7951</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>2004-03-11 13:00:00</td>\n","      <td>1.9</td>\n","      <td>1286.0</td>\n","      <td>63.0</td>\n","      <td>7.3</td>\n","      <td>869.0</td>\n","      <td>146.0</td>\n","      <td>1162.0</td>\n","      <td>112.0</td>\n","      <td>1537.0</td>\n","      <td>799.0</td>\n","      <td>8.3</td>\n","      <td>76.4</td>\n","      <td>0.8393</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>Thursday</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              DateTime  CO(GT)  PT08.S1(CO)  ...  Month  Day   Day Name\n","0  2004-03-10 18:00:00     2.6       1360.0  ...      3   10  Wednesday\n","1  2004-03-10 19:00:00     2.0       1292.0  ...      3   10  Wednesday\n","2  2004-03-10 20:00:00     2.2       1402.0  ...      3   10  Wednesday\n","3  2004-03-10 21:00:00     2.2       1376.0  ...      3   10  Wednesday\n","4  2004-03-10 22:00:00     1.6       1272.0  ...      3   10  Wednesday\n","5  2004-03-10 23:00:00     1.2       1197.0  ...      3   10  Wednesday\n","6  2004-03-11 00:00:00     1.2       1185.0  ...      3   11   Thursday\n","7  2004-03-11 01:00:00     1.0       1136.0  ...      3   11   Thursday\n","8  2004-03-11 02:00:00     0.9       1094.0  ...      3   11   Thursday\n","9  2004-03-11 03:00:00     0.6       1010.0  ...      3   11   Thursday\n","10 2004-03-11 04:00:00  -200.0       1011.0  ...      3   11   Thursday\n","11 2004-03-11 05:00:00     0.7       1066.0  ...      3   11   Thursday\n","12 2004-03-11 06:00:00     0.7       1052.0  ...      3   11   Thursday\n","13 2004-03-11 07:00:00     1.1       1144.0  ...      3   11   Thursday\n","14 2004-03-11 08:00:00     2.0       1333.0  ...      3   11   Thursday\n","15 2004-03-11 09:00:00     2.2       1351.0  ...      3   11   Thursday\n","16 2004-03-11 10:00:00     1.7       1233.0  ...      3   11   Thursday\n","17 2004-03-11 11:00:00     1.5       1179.0  ...      3   11   Thursday\n","18 2004-03-11 12:00:00     1.6       1236.0  ...      3   11   Thursday\n","19 2004-03-11 13:00:00     1.9       1286.0  ...      3   11   Thursday\n","\n","[20 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"hIJc20qpbeJe","executionInfo":{"status":"ok","timestamp":1613471180761,"user_tz":-330,"elapsed":3098,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}}},"source":["# S2.1: Get the descriptive statistics for all the numeric data-type columns.\n","abc = df.describe()"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DYTzyjJXtzsU"},"source":["Except for the `Year, Month` and `Day` columns all the other columns contain the `-200` as its minimum value. Because of this their mean values are also affect. The median value never gets affected due to some garbage value or very high and very low values. So, we can replace `-200` with the median value for each column. \n","\n","But first, let's find out how many rows contain `-200` in each column except for the `DateTime, Year, Month` and `Day` columns."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_itgCcerSvf-","executionInfo":{"status":"ok","timestamp":1613471180762,"user_tz":-330,"elapsed":3083,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"9f642767-63a5-47bc-8090-7186c01040f9"},"source":["df.shape"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9357, 18)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71JSpvBcTFDm","executionInfo":{"status":"ok","timestamp":1613471180762,"user_tz":-330,"elapsed":3072,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"ee8713b1-0254-42ab-aa50-88bcca488021"},"source":["df.columns"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['DateTime', 'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n","       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n","       'PT08.S5(O3)', 'T', 'RH', 'AH', 'Year', 'Month', 'Day', 'Day Name'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"Qp7TOb6nbhy_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181456,"user_tz":-330,"elapsed":3755,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"97864a23-c65a-4fe2-b3de-2229ed18cec6"},"source":["# T2.1: How many rows contain -200 in each column except for the 'DateTime', 'Year', 'Month' and 'Day' columns?\n","a1 = [(i, df[df[i] == -200].shape[0]) for i in df.columns[1:-4]] \n","a1"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('CO(GT)', 1683),\n"," ('PT08.S1(CO)', 366),\n"," ('NMHC(GT)', 8443),\n"," ('C6H6(GT)', 366),\n"," ('PT08.S2(NMHC)', 366),\n"," ('NOx(GT)', 1639),\n"," ('PT08.S3(NOx)', 366),\n"," ('NO2(GT)', 1642),\n"," ('PT08.S4(NO2)', 366),\n"," ('PT08.S5(O3)', 366),\n"," ('T', 366),\n"," ('RH', 366),\n"," ('AH', 366)]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"N4t2hUn8vJRx"},"source":["In the above code:\n","\n","- we iterated through each column having indices between `1` and `-4` (excluding `-4`) in the `df` DataFrame,\n","\n","- retrieved the rows containing `-200` value using the `df[df[col] == -200]` opeartion,\n","\n","- calculated the number of such rows using the `shape[0]` attribute, and\n","\n","- added the column name and the corresponding counts of `-200` in each columnn as a tuple in a list using the list comprehension method.\n","\n","Now, let's also find out the percentage of rows contain `-200` in each column except for the `DateTime, Year, Month` and `Day` columns."]},{"cell_type":"code","metadata":{"id":"F7Me37cnbkEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181457,"user_tz":-330,"elapsed":3744,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"2b3d97fc-eae8-4168-e76d-c30c13c1762b"},"source":["# S2.2: Find out the percentage of rows contain -200 in each column except for the 'DateTime', 'Year', 'Month' and 'Day' columns.\n","a1p =  [(i, round(df[df[i] == -200].shape[0] * 100 / df.shape[0], 2 )) for i in df.columns[1:-4]]\n","a1p "],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('CO(GT)', 17.99),\n"," ('PT08.S1(CO)', 3.91),\n"," ('NMHC(GT)', 90.23),\n"," ('C6H6(GT)', 3.91),\n"," ('PT08.S2(NMHC)', 3.91),\n"," ('NOx(GT)', 17.52),\n"," ('PT08.S3(NOx)', 3.91),\n"," ('NO2(GT)', 17.55),\n"," ('PT08.S4(NO2)', 3.91),\n"," ('PT08.S5(O3)', 3.91),\n"," ('T', 3.91),\n"," ('RH', 3.91),\n"," ('AH', 3.91)]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"HUkd-vEBxVva"},"source":["Using the same process as above, we calculate the percentage of rows contain `-200` in each column except for the `DateTime, Year, Month` and `Day` columns.\n","\n","Now, let's remove all the columns from the `df` DataFrame containing more than 10% garbage value."]},{"cell_type":"code","metadata":{"id":"zJUftyBSbl5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181458,"user_tz":-330,"elapsed":3734,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"5c149b6c-25a7-4c1a-ecf4-0debdca1a3bd"},"source":["# S2.3: Remove all the columns from the 'df' DataFrame containing more than 10% garbage value.\n","df = df.drop(columns = ['CO(GT)', 'NMHC(GT)', 'NOx(GT)','NO2(GT)'], axis = 1)\n","df.columns"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['DateTime', 'PT08.S1(CO)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)',\n","       'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH', 'Year', 'Month', 'Day',\n","       'Day Name'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"rz7evgEOyMpC"},"source":["Again, calculate the percentage of rows contain `-200` in each column except for the `DateTime, Year, Month` and `Day` columns."]},{"cell_type":"code","metadata":{"id":"8fk4W9Yvbobs","executionInfo":{"status":"ok","timestamp":1613471181459,"user_tz":-330,"elapsed":3731,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}}},"source":["# S2.4: Again, calculate the percentage of rows containing '-200' in each column except for the 'DateTime', 'Year', 'Month' and 'Day' columns.\n"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_WQClexBylk7"},"source":["Let's replace the `-200` value with the median values in all the columns except for the `DateTime, Year, Month` and `Day` columns. \n","\n","Before that we should split the entire DataFrame in two different DataFrames because it contains data for two different years, i.e., 2004 and 2005. Then we should calculate the median values for each column for 2004 and 2005 separately. However, we can also first find out whether the median values are actually different for the two years. If they are not, then we don't need to split the DataFrame into two DataFrames for 2004 and 2005 datapoints."]},{"cell_type":"code","metadata":{"id":"9YAwYfI9buN-","colab":{"base_uri":"https://localhost:8080/","height":291},"executionInfo":{"status":"ok","timestamp":1613471181460,"user_tz":-330,"elapsed":3717,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"8244b6ee-dd64-4e46-ab88-f90e16d48f84"},"source":["# T2.2: Calculate the median values for the columns having indices between 1 and -4 (excluding -4) for the year 2004.\n","df.loc[df['Year'] == 2004, df.columns[1:-4]].describe()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PT08.S1(CO)</th>\n","      <th>C6H6(GT)</th>\n","      <th>PT08.S2(NMHC)</th>\n","      <th>PT08.S3(NOx)</th>\n","      <th>PT08.S4(NO2)</th>\n","      <th>PT08.S5(O3)</th>\n","      <th>T</th>\n","      <th>RH</th>\n","      <th>AH</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>7110.000000</td>\n","      <td>7110.000000</td>\n","      <td>7110.00000</td>\n","      <td>7110.000000</td>\n","      <td>7110.000000</td>\n","      <td>7110.000000</td>\n","      <td>7110.000000</td>\n","      <td>7110.000000</td>\n","      <td>7110.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1055.135443</td>\n","      <td>3.876779</td>\n","      <td>923.60661</td>\n","      <td>822.454571</td>\n","      <td>1495.659353</td>\n","      <td>973.985513</td>\n","      <td>13.779001</td>\n","      <td>40.292053</td>\n","      <td>-5.310343</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>314.719517</td>\n","      <td>37.859514</td>\n","      <td>332.55071</td>\n","      <td>315.705690</td>\n","      <td>433.109562</td>\n","      <td>434.094624</td>\n","      <td>39.705743</td>\n","      <td>46.983126</td>\n","      <td>35.441047</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.00000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>919.000000</td>\n","      <td>4.600000</td>\n","      <td>741.00000</td>\n","      <td>666.000000</td>\n","      <td>1331.250000</td>\n","      <td>712.000000</td>\n","      <td>14.300000</td>\n","      <td>33.000000</td>\n","      <td>0.855925</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1052.000000</td>\n","      <td>8.600000</td>\n","      <td>923.00000</td>\n","      <td>815.000000</td>\n","      <td>1528.000000</td>\n","      <td>933.000000</td>\n","      <td>20.150000</td>\n","      <td>47.700000</td>\n","      <td>1.083550</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1221.000000</td>\n","      <td>14.200000</td>\n","      <td>1124.00000</td>\n","      <td>982.000000</td>\n","      <td>1726.000000</td>\n","      <td>1233.750000</td>\n","      <td>25.800000</td>\n","      <td>61.000000</td>\n","      <td>1.404175</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2040.000000</td>\n","      <td>63.700000</td>\n","      <td>2214.00000</td>\n","      <td>2683.000000</td>\n","      <td>2775.000000</td>\n","      <td>2523.000000</td>\n","      <td>44.600000</td>\n","      <td>88.700000</td>\n","      <td>2.231000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PT08.S1(CO)     C6H6(GT)  ...           RH           AH\n","count  7110.000000  7110.000000  ...  7110.000000  7110.000000\n","mean   1055.135443     3.876779  ...    40.292053    -5.310343\n","std     314.719517    37.859514  ...    46.983126    35.441047\n","min    -200.000000  -200.000000  ...  -200.000000  -200.000000\n","25%     919.000000     4.600000  ...    33.000000     0.855925\n","50%    1052.000000     8.600000  ...    47.700000     1.083550\n","75%    1221.000000    14.200000  ...    61.000000     1.404175\n","max    2040.000000    63.700000  ...    88.700000     2.231000\n","\n","[8 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"oTxCmCsjbwGj","colab":{"base_uri":"https://localhost:8080/","height":291},"executionInfo":{"status":"ok","timestamp":1613471181461,"user_tz":-330,"elapsed":3705,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"5f05663b-2b12-4fb8-ce3e-7b0cbb6fa5ae"},"source":["# S2.5: Calculate the median values for the columns having indices between 1 and -4 (excluding -4) for the year 2005.\n","df.loc[df['Year'] == 2005, df.columns[1:-4]].describe()"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PT08.S1(CO)</th>\n","      <th>C6H6(GT)</th>\n","      <th>PT08.S2(NMHC)</th>\n","      <th>PT08.S3(NOx)</th>\n","      <th>PT08.S4(NO2)</th>\n","      <th>PT08.S5(O3)</th>\n","      <th>T</th>\n","      <th>RH</th>\n","      <th>AH</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","      <td>2247.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1029.544726</td>\n","      <td>-4.497864</td>\n","      <td>802.797063</td>\n","      <td>708.086782</td>\n","      <td>1061.832221</td>\n","      <td>978.510013</td>\n","      <td>-2.880774</td>\n","      <td>36.932888</td>\n","      <td>-11.670190</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>373.059005</td>\n","      <td>50.426047</td>\n","      <td>356.435107</td>\n","      <td>326.303957</td>\n","      <td>415.312391</td>\n","      <td>522.776411</td>\n","      <td>50.737736</td>\n","      <td>62.700754</td>\n","      <td>48.186199</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","      <td>-200.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>925.500000</td>\n","      <td>2.900000</td>\n","      <td>643.500000</td>\n","      <td>553.500000</td>\n","      <td>906.000000</td>\n","      <td>641.000000</td>\n","      <td>4.700000</td>\n","      <td>37.200000</td>\n","      <td>0.413350</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1055.000000</td>\n","      <td>5.800000</td>\n","      <td>805.000000</td>\n","      <td>721.000000</td>\n","      <td>1084.000000</td>\n","      <td>973.000000</td>\n","      <td>8.600000</td>\n","      <td>50.900000</td>\n","      <td>0.596400</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1222.000000</td>\n","      <td>11.200000</td>\n","      <td>1021.500000</td>\n","      <td>893.500000</td>\n","      <td>1297.000000</td>\n","      <td>1344.500000</td>\n","      <td>13.400000</td>\n","      <td>64.750000</td>\n","      <td>0.804950</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1846.000000</td>\n","      <td>43.000000</td>\n","      <td>1831.000000</td>\n","      <td>1881.000000</td>\n","      <td>2147.000000</td>\n","      <td>2494.000000</td>\n","      <td>30.000000</td>\n","      <td>86.600000</td>\n","      <td>1.393000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PT08.S1(CO)     C6H6(GT)  ...           RH           AH\n","count  2247.000000  2247.000000  ...  2247.000000  2247.000000\n","mean   1029.544726    -4.497864  ...    36.932888   -11.670190\n","std     373.059005    50.426047  ...    62.700754    48.186199\n","min    -200.000000  -200.000000  ...  -200.000000  -200.000000\n","25%     925.500000     2.900000  ...    37.200000     0.413350\n","50%    1055.000000     5.800000  ...    50.900000     0.596400\n","75%    1222.000000    11.200000  ...    64.750000     0.804950\n","max    1846.000000    43.000000  ...    86.600000     1.393000\n","\n","[8 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"DY8W_2ge0yil"},"source":["As we can see, the median values for 2004 and 2005 are different. Hence, we should split the `df` DataFrame into two different DataFrames. One for 2004 datapoints and another for 2005 datapoints."]},{"cell_type":"markdown","metadata":{"id":"Xv6z2R3j1el6"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"lBEtpZ5xb1MO"},"source":["#### Activity 3: Garbage Value Replacement^^^\n","\n","Before we separate the DataFrame, let's calculate the count of 2004 and 2005 datapoints."]},{"cell_type":"code","metadata":{"id":"1HCdKdb8bsZF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181461,"user_tz":-330,"elapsed":3691,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"1f912968-135c-4ec4-8694-e8acdd4884f7"},"source":["# S3.1: Count the number of rows containing '2004' and '2005' year values.\n","df[\"Year\"].value_counts()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2004    7110\n","2005    2247\n","Name: Year, dtype: int64"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"LfSNiYOVzbLI"},"source":["The DataFrame for 2004 year should have 7110 rows which means the DataFrame for 2005 year should have 2247 rows."]},{"cell_type":"code","metadata":{"id":"DX_N7oKjb19r","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"ok","timestamp":1613471181462,"user_tz":-330,"elapsed":3675,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"60e364c0-9eea-4336-b8dd-c2bea9ac3bca"},"source":["# S3.2: Create a new DataFrame containing records for the year 2004. Also, display the first five rows.\n","df_2004 = df[df['Year'] == 2004]\n","df_2004.head()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DateTime</th>\n","      <th>PT08.S1(CO)</th>\n","      <th>C6H6(GT)</th>\n","      <th>PT08.S2(NMHC)</th>\n","      <th>PT08.S3(NOx)</th>\n","      <th>PT08.S4(NO2)</th>\n","      <th>PT08.S5(O3)</th>\n","      <th>T</th>\n","      <th>RH</th>\n","      <th>AH</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>Day Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2004-03-10 18:00:00</td>\n","      <td>1360.0</td>\n","      <td>11.9</td>\n","      <td>1046.0</td>\n","      <td>1056.0</td>\n","      <td>1692.0</td>\n","      <td>1268.0</td>\n","      <td>13.6</td>\n","      <td>48.9</td>\n","      <td>0.7578</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2004-03-10 19:00:00</td>\n","      <td>1292.0</td>\n","      <td>9.4</td>\n","      <td>955.0</td>\n","      <td>1174.0</td>\n","      <td>1559.0</td>\n","      <td>972.0</td>\n","      <td>13.3</td>\n","      <td>47.7</td>\n","      <td>0.7255</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2004-03-10 20:00:00</td>\n","      <td>1402.0</td>\n","      <td>9.0</td>\n","      <td>939.0</td>\n","      <td>1140.0</td>\n","      <td>1555.0</td>\n","      <td>1074.0</td>\n","      <td>11.9</td>\n","      <td>54.0</td>\n","      <td>0.7502</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004-03-10 21:00:00</td>\n","      <td>1376.0</td>\n","      <td>9.2</td>\n","      <td>948.0</td>\n","      <td>1092.0</td>\n","      <td>1584.0</td>\n","      <td>1203.0</td>\n","      <td>11.0</td>\n","      <td>60.0</td>\n","      <td>0.7867</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2004-03-10 22:00:00</td>\n","      <td>1272.0</td>\n","      <td>6.5</td>\n","      <td>836.0</td>\n","      <td>1205.0</td>\n","      <td>1490.0</td>\n","      <td>1110.0</td>\n","      <td>11.2</td>\n","      <td>59.6</td>\n","      <td>0.7888</td>\n","      <td>2004</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>Wednesday</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             DateTime  PT08.S1(CO)  C6H6(GT)  ...  Month  Day   Day Name\n","0 2004-03-10 18:00:00       1360.0      11.9  ...      3   10  Wednesday\n","1 2004-03-10 19:00:00       1292.0       9.4  ...      3   10  Wednesday\n","2 2004-03-10 20:00:00       1402.0       9.0  ...      3   10  Wednesday\n","3 2004-03-10 21:00:00       1376.0       9.2  ...      3   10  Wednesday\n","4 2004-03-10 22:00:00       1272.0       6.5  ...      3   10  Wednesday\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"OfIamjv9b4iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181463,"user_tz":-330,"elapsed":3666,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"471eb585-b7d5-4f57-fcb7-f69e59b5dc91"},"source":["# S3.3 Calculate the number of rows and columns in the DataFrame for the 2004 year records.\n","df_2004.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7110, 14)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"OV-LTYaCb6eI","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"ok","timestamp":1613471181464,"user_tz":-330,"elapsed":3657,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"4d216538-255c-474f-8963-312ec1069793"},"source":["# S3.4: Create a new DataFrame containing records for the year 2005. Also, display the first five rows.\n","df_2005 = df[df['Year'] == 2005]\n","df_2005.head()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DateTime</th>\n","      <th>PT08.S1(CO)</th>\n","      <th>C6H6(GT)</th>\n","      <th>PT08.S2(NMHC)</th>\n","      <th>PT08.S3(NOx)</th>\n","      <th>PT08.S4(NO2)</th>\n","      <th>PT08.S5(O3)</th>\n","      <th>T</th>\n","      <th>RH</th>\n","      <th>AH</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>Day Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7110</th>\n","      <td>2005-01-01 00:00:00</td>\n","      <td>1046.0</td>\n","      <td>4.2</td>\n","      <td>724.0</td>\n","      <td>848.0</td>\n","      <td>898.0</td>\n","      <td>1201.0</td>\n","      <td>8.2</td>\n","      <td>40.1</td>\n","      <td>0.4375</td>\n","      <td>2005</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Saturday</td>\n","    </tr>\n","    <tr>\n","      <th>7111</th>\n","      <td>2005-01-01 01:00:00</td>\n","      <td>1275.0</td>\n","      <td>8.8</td>\n","      <td>930.0</td>\n","      <td>649.0</td>\n","      <td>1024.0</td>\n","      <td>1617.0</td>\n","      <td>5.3</td>\n","      <td>50.7</td>\n","      <td>0.4564</td>\n","      <td>2005</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Saturday</td>\n","    </tr>\n","    <tr>\n","      <th>7112</th>\n","      <td>2005-01-01 02:00:00</td>\n","      <td>1173.0</td>\n","      <td>7.5</td>\n","      <td>878.0</td>\n","      <td>738.0</td>\n","      <td>1002.0</td>\n","      <td>1355.0</td>\n","      <td>5.9</td>\n","      <td>50.0</td>\n","      <td>0.4689</td>\n","      <td>2005</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Saturday</td>\n","    </tr>\n","    <tr>\n","      <th>7113</th>\n","      <td>2005-01-01 03:00:00</td>\n","      <td>1163.0</td>\n","      <td>7.6</td>\n","      <td>881.0</td>\n","      <td>748.0</td>\n","      <td>1001.0</td>\n","      <td>1296.0</td>\n","      <td>4.9</td>\n","      <td>53.9</td>\n","      <td>0.4693</td>\n","      <td>2005</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Saturday</td>\n","    </tr>\n","    <tr>\n","      <th>7114</th>\n","      <td>2005-01-01 04:00:00</td>\n","      <td>1054.0</td>\n","      <td>5.6</td>\n","      <td>791.0</td>\n","      <td>830.0</td>\n","      <td>967.0</td>\n","      <td>1131.0</td>\n","      <td>4.3</td>\n","      <td>55.3</td>\n","      <td>0.4650</td>\n","      <td>2005</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Saturday</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                DateTime  PT08.S1(CO)  C6H6(GT)  ...  Month  Day  Day Name\n","7110 2005-01-01 00:00:00       1046.0       4.2  ...      1    1  Saturday\n","7111 2005-01-01 01:00:00       1275.0       8.8  ...      1    1  Saturday\n","7112 2005-01-01 02:00:00       1173.0       7.5  ...      1    1  Saturday\n","7113 2005-01-01 03:00:00       1163.0       7.6  ...      1    1  Saturday\n","7114 2005-01-01 04:00:00       1054.0       5.6  ...      1    1  Saturday\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"LGMt9A_hb-Ma","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181464,"user_tz":-330,"elapsed":3648,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"c2921263-74ce-444c-af56-91d2f4ef3f6f"},"source":["# S3.5 Calculate the number of rows and columns in the DataFrame for the 2004 year records.\n","df_2005.shape"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2247, 14)"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"ebn1SrZC2qZF"},"source":["Now, let's replace the `-200` value with the median values for each column having indices between 1 and -4 (excluding -4) for both the 2004 and 2005 year DataFrames."]},{"cell_type":"code","metadata":{"id":"z_L4Vk0LcCDm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181466,"user_tz":-330,"elapsed":3638,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"6cdd28eb-b9dc-4ea7-c63d-678d7f3de9d3"},"source":["# T3.1: Replace the -200 value with the median values for each column having indices between 1 and -4 (excluding -4) for the 2004 year DataFrame.\n","for i in df_2004.columns[1:-4]:\n","  m_v = df_2004[i].median()\n","  df_2004[i] = df_2004[i].replace(to_replace = -200, value = m_v )\n","#df_2004.head(20)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"h5Gx_ITdueGS"},"source":["```\n","import warnings\n","warnings.filterwarnings('ignore')\n","```\n","\n","The above code will remove all the warnings that we may get."]},{"cell_type":"code","metadata":{"id":"c3-WHh7lcGNy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181467,"user_tz":-330,"elapsed":3622,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"4cf24757-9e85-4da5-db52-eac07f4b9ca3"},"source":["# S3.6: Repeat the same exercise for the 2005 year DataFrame.\n","for i in df_2005.columns[1:-4]:\n","  mv = df_2005[i].median()\n","  df_2005[i] = df_2005[i].replace(to_replace = -200, value = mv )"],"execution_count":45,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"5yHuQJOI31t_"},"source":["Now, let's again, calculate the number of rows containing '-200' in each column except for the `DateTime, Year, Month` and `Day` columns in both the DataFrames."]},{"cell_type":"code","metadata":{"id":"tbefMOs_cILq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471181468,"user_tz":-330,"elapsed":3604,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"52eaf9e6-f267-4ddb-ee99-4e1cb95ba1a5"},"source":["# S3.7: Compute the number of rows containing '-200' in each column having indices between 1 and -4 (excluding -4) in the 2004 year DataFrame.\n","a2 = [(i, df_2004[df_2004[i] == -200].shape[0]) for i in df.columns[1:-4]] \n","a2"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('PT08.S1(CO)', 0),\n"," ('C6H6(GT)', 0),\n"," ('PT08.S2(NMHC)', 0),\n"," ('PT08.S3(NOx)', 0),\n"," ('PT08.S4(NO2)', 0),\n"," ('PT08.S5(O3)', 0),\n"," ('T', 0),\n"," ('RH', 0),\n"," ('AH', 0)]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"YkW93PNTcKtg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613471266821,"user_tz":-330,"elapsed":998,"user":{"displayName":"Arhan Singhal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4PdbuZAsAVBem9gfXxGllkTugQRSsMItz_luU=s64","userId":"10909470486853968911"}},"outputId":"d68bd374-7031-410b-8eee-c97f72fb456b"},"source":["# S3.8: Again, calculate the percentage of rows containing '-200' in each column except for the 'DateTime', 'Year', 'Month' and 'Day' columns.\n","perc = [(i, round(df_2004[df_2004[i] == -200].shape[0]*100/df.shape[0],2)) for i in df.columns[1:-4]]\n","perc"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('PT08.S1(CO)', 0.0),\n"," ('C6H6(GT)', 0.0),\n"," ('PT08.S2(NMHC)', 0.0),\n"," ('PT08.S3(NOx)', 0.0),\n"," ('PT08.S4(NO2)', 0.0),\n"," ('PT08.S5(O3)', 0.0),\n"," ('T', 0.0),\n"," ('RH', 0.0),\n"," ('AH', 0.0)]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"9QvvVwQ056a5"},"source":["Let's pause here. In the next class, we will learn how to group a DataFrame about a particular column to perform aggregation operations such as count, mean, median and sum. "]},{"cell_type":"markdown","metadata":{"id":"XdlP6if3554T"},"source":["---"]}]}